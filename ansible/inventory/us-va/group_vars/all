
bind_address: "{{ ansible_eth0.ipv4.address }}"

consul_ips:
  - 10.0.5.56
  - 10.0.5.57
  - 10.0.5.58
  - 8.8.8.8

customer_id: test

datacenter: "oss-va1"

# curator_run_frequency in minutes
elasticsearch:
  user: elastic
  pass: changeme
  curator_run_frequency: 5
  index_purge_older_than: 5
  cluster_name: "ccf-{{ customer_id }}"
  consul_service: "elasticsearch_{{ customer_id }}"
  index_purge_more_than_gb: 450

step -1.
  c1
    # of cluster nodes: 1....n  (this is master)
    # of replicas: 1...n
    Amount of storage for retention: xGB
    Length of retention: nDays
    # of data nodes: 1...n (if cluster nodes ==1, then both master and data will be same container)
    mem cap for each container: XGB
step 1.
    x-pack: y/n
    if x-pack:
      uname: auto gen
      pwd: auto gen
      svc uname: auto gen
      svc pwd: auto gen
    else:
      no creds

step 0.
  Inv:
    3 Nodes for ES
    calculator says: 10 containers (5 masters, 5 data)
      - Not supported: Since we dont want to run multiple data containers on the same host for the same customer.
      - Max we can do is: ES host count (1..3 masters, 1..3 data)
    If docker not installed, then error out.
    round robin to each host and deploy for that customer finding a port that is open.
      masters first and then data containers
    Kibana/Dashboard container will be deployed on a open port on the dashboard server

  c1.index size per container: 50gb
  c1.max index size: 300gb

  6 data nodes...
  3 hosts
  2 data nodes on each...



openstack:
  auth_url: https://us-virginia-1.cloud.cisco.com:5000/v2.0/
  availability_zone: iad10-1-csx
  image: 9e252722-8a63-43a5-bee3-c6a88e543513
  tenant: OSS-20-Testing-64156
  nodes_flavor: SO3-Large
  key_name: oss20
  auto_ip: no
  security_groups:
    - default

environment:
  OS_USERNAME: oss-service.gen
  OS_PASSWORD: a5459a96921c422497aa721bbb1a6c91
  OS_AUTH_URL: "{{ openstack.auth_url }}"
  OS_TENANT_NAME: "{{ openstack.tenant }}"

remote_user: "cloud-user"
